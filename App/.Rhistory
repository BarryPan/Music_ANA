),
mainPanel(
# show plots
tabsetPanel(
tabPanel("Original Text", value = 1, verbatimTextOutput("value")),
tabPanel("Frequency Table", dataTableOutput("table1")),
tabPanel("Histogram", value = 2, plotOutput("plot1")),
tabPanel("Word Cloud", value = 3, plotOutput("plot2")),
tabPanel("Hierarchical Clustering", value = 4, plotOutput("plot3")),
tabPanel("KMeans", value = 5, plotOutput("plot4")),
tabPanel("Network", value = 6, plotOutput("plot5")),
id = "conditionedPanels"
)
)
),
server = function(input, output, session) {
file = reactive(input$file)
data = reactive({
if (is.null(file())){
NULL
} else {
readLines(file()$datapath) %>% as.list()
}
})
output$value = renderPrint(
data()
)
data = reactive({readLines(file()$datapath) %>% as.list})
myDtm = reactive({
clean_data = clean_text(data())
stem(clean_data)
})
df = reactive({
freq_table(myDtm())
})
output$table1 = renderDataTable(
df()
)
output$plot1 = renderPlot({
hist_data = df()[1:input$n1,]
ggplot(hist_data, aes(reorder(word, -freq), freq))+
geom_bar(stat="identity") +
theme_minimal() +
theme(axis.text.x=element_text(angle=45, hjust=1)) +
ylab("Frequency") + xlab("")
})
output$plot2 = renderPlot({
wordcloud(df()$word, df()$freq,
max.words = input$n2, scale = c(4,0.5),
colors = brewer.pal(8, "Dark2") )
})
dtmss = reactive({
removeSparseTerms(myDtm(), input$sparsity)
})
d = reactive(dist((dtmss()), method = "euclidian"))
fit = reactive(hclust(d = d(), method = "ward.D"))
output$plot3 = renderPlot({
# remove sparse terms
plot(fit(), hang=-1, xlab = "", sub ="")
rect.hclust(fit(), input$k, border="red") # draw dendogram with red borders around the 5 clusters
groups = cutree(fit(), input$k)   # "k=" defines the number of clusters you are using
})
output$plot4 = renderPlot({
kfit = kmeans(d(), input$k)
clusplot(as.matrix(d()), kfit$cluster, main = "",
color=T, shade=T, labels=2, lines=0)
})
output$plot5  = renderPlot({
termDocMatrix = as.matrix(dtmss())
termDocMatrix[termDocMatrix>=1] = 1
termMatrix = termDocMatrix %*% t(termDocMatrix)
g = graph.adjacency(termMatrix, weighted=T, mode = "undirected")
V(g)$label = V(g)$name
V(g)$degree = degree(g)
# remove loops
g = simplify(g)
V(g)$label.cex = log(rank(V(g)$degree)) + 1
V(g)$label.color = rgb(0, 0, .2, .8)
V(g)$frame.color = NA
egam = (log(E(g)$weight)+.4) / max(log(E(g)$weight)+.4)
E(g)$color = rgb(.5, .5, 0, egam)
E(g)$width = egam*2
plot(g)
})
observe({
input$reset
session$sendCustomMessage(type = "resetFileInputHandler", "file")
})
}
)
install.packages("wordcloud")
library(wordcloud)
# call shiny app
shinyApp(
ui = fluidPage(
titlePanel("Text Miner"),
hr(),
sidebarPanel(
# select a file
fileInput("file", label = h3("Source"), multiple = FALSE),
# add a reset button
actionButton("reset", "Reset File"),
# reset fileInput
tags$script('
Shiny.addCustomMessageHandler("resetFileInputHandler", function(x) {
var id = "#" + x + "_progress";
var idBar = id + " .bar";
$(id).css("visibility", "hidden");
$(idBar).css("width", "0%");
});
'),
# parameters for each plot
conditionalPanel(condition="input.conditionedPanels==2",
hr(),
h3("Parameters"),
helpText("Number of Most Frequent Words"),
sliderInput("n1", label = "", min = 1, max = 100,
value = 20, step = 1)),
conditionalPanel(condition="input.conditionedPanels==3",
hr(),
h3("Parameters"),
helpText("Number of Most Frequent Words"),
sliderInput("n2", label = "", min = 1, max = 100,
value = 50, step = 1)),
conditionalPanel(condition="input.conditionedPanels == 4 ||
input.conditionedPanels == 5||input.conditionedPanels == 6",
hr(),
h3("Parameters"),
helpText("Sparsity"),
sliderInput("sparsity", label = "", min = 0, max = 1,
value = 0.87, step = 0.01)),
conditionalPanel(condition="input.conditionedPanels==4 || input.conditionedPanels==5",
hr(),
helpText("Number of clusters"),
sliderInput("k", label = "", min = 1, max = 10,
value = 5, step = 1))
),
mainPanel(
# show plots
tabsetPanel(
tabPanel("Original Text", value = 1, verbatimTextOutput("value")),
tabPanel("Frequency Table", dataTableOutput("table1")),
tabPanel("Histogram", value = 2, plotOutput("plot1")),
tabPanel("Word Cloud", value = 3, plotOutput("plot2")),
tabPanel("Hierarchical Clustering", value = 4, plotOutput("plot3")),
tabPanel("KMeans", value = 5, plotOutput("plot4")),
tabPanel("Network", value = 6, plotOutput("plot5")),
id = "conditionedPanels"
)
)
),
server = function(input, output, session) {
file = reactive(input$file)
data = reactive({
if (is.null(file())){
NULL
} else {
readLines(file()$datapath) %>% as.list()
}
})
output$value = renderPrint(
data()
)
data = reactive({readLines(file()$datapath) %>% as.list})
myDtm = reactive({
clean_data = clean_text(data())
stem(clean_data)
})
df = reactive({
freq_table(myDtm())
})
output$table1 = renderDataTable(
df()
)
output$plot1 = renderPlot({
hist_data = df()[1:input$n1,]
ggplot(hist_data, aes(reorder(word, -freq), freq))+
geom_bar(stat="identity") +
theme_minimal() +
theme(axis.text.x=element_text(angle=45, hjust=1)) +
ylab("Frequency") + xlab("")
})
output$plot2 = renderPlot({
wordcloud(df()$word, df()$freq,
max.words = input$n2, scale = c(4,0.5),
colors = brewer.pal(8, "Dark2") )
})
dtmss = reactive({
removeSparseTerms(myDtm(), input$sparsity)
})
d = reactive(dist((dtmss()), method = "euclidian"))
fit = reactive(hclust(d = d(), method = "ward.D"))
output$plot3 = renderPlot({
# remove sparse terms
plot(fit(), hang=-1, xlab = "", sub ="")
rect.hclust(fit(), input$k, border="red") # draw dendogram with red borders around the 5 clusters
groups = cutree(fit(), input$k)   # "k=" defines the number of clusters you are using
})
output$plot4 = renderPlot({
kfit = kmeans(d(), input$k)
clusplot(as.matrix(d()), kfit$cluster, main = "",
color=T, shade=T, labels=2, lines=0)
})
output$plot5  = renderPlot({
termDocMatrix = as.matrix(dtmss())
termDocMatrix[termDocMatrix>=1] = 1
termMatrix = termDocMatrix %*% t(termDocMatrix)
g = graph.adjacency(termMatrix, weighted=T, mode = "undirected")
V(g)$label = V(g)$name
V(g)$degree = degree(g)
# remove loops
g = simplify(g)
V(g)$label.cex = log(rank(V(g)$degree)) + 1
V(g)$label.color = rgb(0, 0, .2, .8)
V(g)$frame.color = NA
egam = (log(E(g)$weight)+.4) / max(log(E(g)$weight)+.4)
E(g)$color = rgb(.5, .5, 0, egam)
E(g)$width = egam*2
plot(g)
})
observe({
input$reset
session$sendCustomMessage(type = "resetFileInputHandler", "file")
})
}
)
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(repr)
library(sqldf)
library(reshape)
library(zoo)
library(dplyr)
library(corrplot)
library(fpp2)
library(stargazer)
data = read.csv("assessment_data.tsv",sep = '\t', header = TRUE)
data2 = data[!is.na(data$tickets_listed),]
pred_data = data[is.na(data$tickets_listed),]
stargazer(sqldf('select venue_name, taxonomy , count(*) as Num, avg(tickets_listed) as Avg_Tickets, avg(mean_listing_price) as Avg_Price from data2 group by venue_name, taxonomy'),summary=F,type="text")
data2[,"event_datetime"] = as.POSIXct(data2[,'event_datetime'],format="%Y-%m-%dT%H:%M:%SZ")
data2[,"event_hour"] = as.numeric(format(data2[,"event_datetime"],"%H"))
data2[,"event_date"] = as.Date(format(data2[,"event_datetime"],"%Y-%m-%d"))
stargazer(sqldf('select event_hour, count(*) as Num, avg(tickets_listed) as Avg_Tickets, avg(mean_listing_price) as Avg_Price from data2 group by event_hour'),summary=F,type="text")
stargazer(sqldf("select taxonomy, performer_1, count(distinct event_id) as Cnt, avg(mean_listing_price) as Avg_Price from data2 group by taxonomy, performer_1"),summary=F,type="text")
# Split data by event_id
Sdata = split(data2,data2$event_id)
summary(sapply(Sdata,dim)[1,])
select = which(sapply(Sdata,dim)[1,] > 50)
select_id = names(Sdata[select])
lapply(names(Sdata[select_id]), function(x) assign(paste('T',x,sep=''), as.data.frame(Sdata[[x]]), envir = .GlobalEnv))
# make a dictionary for event
select_id_df = as.data.frame(select_id)
dict = sqldf("select distinct event_id, taxonomy,performer_1 from data2 where event_id in (select * from select_id_df)")
list_data = as.data.frame(unique(data2$listing_date))
names(list_data) = "date"
for (id in select_id){
var = paste("T",id,sep="")
sql = paste("select t1.*, t2.tickets_listed as",var,"from list_data t1 left join",var,"t2 on t1.date = t2.listing_date",sep=" ")
list_data = sqldf(sql)
}
price_data = as.data.frame(unique(data2$listing_date))
names(price_data) = "date"
for (id in select_id){
var = paste("T",id,sep="")
sql = paste("select t1.*, t2.mean_listing_price as",var,"from price_data t1 left join",var,"t2 on t1.date = t2.listing_date",sep=" ")
price_data = sqldf(sql)
}
Performer_Ref = sqldf('select distinct event_id, taxonomy, performer_1, performer_2 from data2')
Performer_Ref["event_id"] = paste("T",Performer_Ref$event_id,sep="")
print("list_data")
stargazer(list_data[c(1:5),c(1:5)],summary=F,type="text")
print("price_data")
stargazer(price_data[c(1:5),c(1:5)],summary=F,type="text")
order_id = sqldf("select event_id, taxonomy from dict order by taxonomy")
M = cor(apply(list_data[,paste("T",order_id$event_id,sep="")],2,na.locf))
corrplot(M,method="square",tl.pos="n")
O_id = dict[dict$taxonomy == "Classical Orchestral","event_id"]
O_id = c("date",paste("T",O_id,sep=""))
O_list = melt(list_data[,O_id],id="date")
ggplot(data=O_list,aes(date,value,group=variable))+geom_line(color="blue")+theme(axis.ticks.x = element_blank(),
axis.text.x = element_blank())+ggtitle("Orchestral")
M_id = dict[dict$taxonomy == "MLB Baseball","event_id"]
M_id = c("date",paste("T",M_id,sep=""))
M_list = melt(list_data[,M_id],id="date")
ggplot(data=M_list,aes(date,value,group=variable))+geom_line(color='blue')+theme(axis.ticks.x = element_blank(),
axis.text.x = element_blank())+ggtitle("MLB")
Min_id = dict[dict$taxonomy == "Minor League Baseball","event_id"]
Min_id = c("date",paste("T",Min_id,sep=""))
Min_list = melt(list_data[,Min_id],id="date")
ggplot(data=Min_list,aes(date,value,group=variable))+geom_line(color='blue')+theme(axis.ticks.x = element_blank(),
axis.text.x = element_blank())+ggtitle("Minor League")
O_list2 = list_data[,O_id]
O_list2["date"] = as.Date(as.character(O_list2$date),format = "%Y-%m-%d")
x = apply(O_list2[,-1],2,diff)
Dif_O_list2 = as.data.frame(x,row.names = as.character(O_list2$date[-1]))
dif_time = as.data.frame(apply(Dif_O_list2,1,function(x) sum(ifelse(-x>5,1,0)))) # major drops on 6/7/2017, 6/8/2017, 6/14/2017, 6/23/2017
ggplot()+geom_line(aes(row.names(dif_time),dif_time,group=1))+
theme(axis.text.x = element_text(size=5,angle=90))+ggtitle("Orchestral")+xlab("date")+ylab("")
M_list2 = list_data[,M_id]
M_list2["date"] = as.Date(as.character(M_list2$date),format = "%Y-%m-%d")
x = apply(M_list2[,-1],2,diff)
Dif_M_list2 = as.data.frame(x,row.names = as.character(M_list2$date[-1]))
dif_time = as.data.frame(apply(Dif_M_list2,1,function(x) sum(ifelse(-x>1000,1,0)))) # major drops in 6/6/2017, 6/7/2017, 6/23/2017,7/18/2017
ggplot()+geom_line(aes(row.names(dif_time),dif_time,group=1))+
theme(axis.text.x = element_text(size=5,angle=90))+ggtitle("MLB")+xlab("date")+ylab("")
M = cor(apply(price_data[,paste("T",order_id$event_id,sep="")],2,na.locf))
corrplot(M,method="square",tl.pos="n")
O_price = melt(price_data[,O_id],id="date")
ggplot(data=O_price,aes(date,value,group=variable))+geom_line(color="red")+theme(axis.ticks.x = element_blank(),
axis.text.x = element_blank())+ggtitle("Orchestral")
# MLB
M_price = melt(price_data[,M_id],id="date")
ggplot(data=M_price,aes(date,value,group=variable))+geom_line(color="red")+theme(axis.ticks.x = element_blank(),
axis.text.x = element_blank())+ggtitle("MLB")
# Minor League
# Oklahoma City Dodger has goes up in the recent dates
Min_price = melt(price_data[,Min_id],id="date")
ggplot(data=Min_price,aes(date,value,group=variable))+geom_line(color="red")+theme(axis.ticks.x = element_blank(),
axis.text.x = element_blank())+ggtitle("Minor League")
O_price2 = price_data[,O_id]
O_price2["date"] = as.Date(as.character(O_price2$date),format = "%Y-%m-%d")
x = apply(O_price2[,-1],2,diff)
Dif_O_price2 = as.data.frame(x,row.names = as.character(O_price2$date[-1]))
dif_time = as.data.frame(apply(Dif_O_price2,1,function(x) sum(ifelse(-x>200,1,0)))) # major drops on 6/14/2017, 6/23/2017
ggplot()+geom_line(aes(row.names(dif_time),dif_time,group=1))+
theme(axis.text.x = element_text(size=5,angle=90))+xlab("date")+ylab("")
source("functions.R")
O_id = dict[dict$taxonomy == "Classical Orchestral","event_id"]
O_id = c("date",paste("T",O_id,sep=""))
O_list = list_data[,O_id]
O_Model_Outcome = apply(O_list[,-1],2,function(x) best_model(compare(na.locf(x))))
stargazer(as.data.frame(table(O_Model_Outcome)),summary=F,type="text")
M_id = dict[dict$taxonomy == "MLB Baseball","event_id"]
M_id = c("date",paste("T",M_id,sep=""))
M_list = list_data[,M_id]
M_Model_Outcome = apply(M_list[,-1],2,function(x) best_model(compare(na.locf(x))))
stargazer(as.data.frame(table(M_Model_Outcome)),summary=F,type="text")
Min_id = dict[dict$taxonomy == "Minor League Baseball","event_id"]
Min_id = c("date",paste("T",Min_id,sep=""))
Min_list = list_data[,Min_id]
Min_Model_Outcome = apply(Min_list[,-1],2,function(x) best_model(compare(na.locf(x))))
stargazer(as.data.frame(table(Min_Model_Outcome)),summary=F,type="text")
O_price = price_data[,O_id]
O_Model_Outcome_p = apply(O_price[,-1],2,function(x) best_model(compare(na.locf(x))))
stargazer(as.data.frame(table(O_Model_Outcome_p)),summary=F,type="text")
M_price = price_data[,M_id]
M_Model_Outcome_p = apply(M_price[,-1],2,function(x) best_model(compare(na.locf(x))))
stargazer(as.data.frame(table(M_Model_Outcome_p)),summary=F,type="text")
Min_price = price_data[,Min_id]
Min_Model_Outcome_p = apply(Min_price[,-1],2,function(x) best_model(compare(na.locf(x))))
stargazer(as.data.frame(table(Min_Model_Outcome_p)),summary=F,type="text")
avg_tb = sqldf("select taxonomy, avg(tickets_listed) as Avg_Ticket_Listed, avg(mean_listing_price) as Avg_Price from data2 group by taxonomy")
avg_tb[is.na(avg_tb[,1]),1] = 'None'
stargazer(avg_tb,summary=F,type="text")
pipeline = function(x,names){
test_data = as.data.frame(x)
names(test_data) = names
test_data = test_data[order(test_data$listing_date),]
type = as.character(unique(test_data$taxonomy))
train = test_data[!is.na(test_data["tickets_listed"]),]
test = test_data[is.na(test_data["tickets_listed"]),]
n_train = dim(train)[1]
n_test = dim(test)[1]
if(n_test == 0){
return(test_data)
}else if(n_train >= 20){
select_model_list = best_model(compare(na.locf(train["tickets_listed"])))
select_model_price = best_model(compare(na.locf(train["mean_listing_price"])))
if(select_model_list == "ARIMA"){
est_list = auto_estimate(train["tickets_listed"],n=n_test)
}else if(select_model_list == "ETS"){
est_list = ets_estimate(train["tickets_listed"],n=n_test)
}else if(select_model_list == "NAIVE"){
est_list = naive_estimate(train["tickets_listed"],n=n_test)
}else if(select_model_list == "HOLT"){
est_list = holt_estimate(train["tickets_listed"],n=n_test)
}
if(select_model_price == "ARIMA"){
est_price = auto_estimate(train["mean_listing_price"],n=n_test)
}else if(select_model_price == "ETS"){
est_price = ets_estimate(train["mean_listing_price"],n=n_test)
}else if(select_model_price == "NAIVE"){
est_price = naive_estimate(train["mean_listing_price"],n=n_test)
}else if(select_model_price == "HOLT"){
est_price = holt_estimate(train["mean_listing_price"],n=n_test)
}
all_list = c(train$tickets_listed,est_list)
all_price = c(train$mean_listing_price,est_price)
test_data["tickets_listed"] = all_list
test_data["mean_listing_price"] = all_price
return(test_data)
}else if(n_train > 10){
est_list = auto_estimate(train["tickets_listed"],n=n_test)
est_price = auto_estimate(train["mean_listing_price"],n=n_test)
all_list = c(train$tickets_listed,est_list)
all_price = c(train$mean_listing_price,est_price)
test_data["tickets_listed"] = all_list
test_data["mean_listing_price"] = all_price
return(test_data)
}else if(n_train > 5){
mean_list = mean(train["tickets_listed"])
mean_price = mean(train["mean_listing_price"])
est_list = rep(mean_list,n_test)
est_price = rep(mean_price,n_test)
all_list = c(train$tickets_listed,est_list)
all_price = c(train$mean_listing_price,est_price)
test_data["tickets_listed"] = all_list
test_data["mean_listing_price"] = all_price
return(test_data)
}else{
pred_list = avg_tb[avg_tb$taxonomy == type,"Avg_Ticket_Listed"]
pred_price = avg_tb[avg_tb$taxonomy == type,"Avg_Price"]
est_list = rep(pred_list,n_test)
est_price = rep(pred_price,n_test)
all_list = c(train$tickets_listed,est_list)
all_price = c(train$mean_listing_price,est_price)
test_data["tickets_listed"] = all_list
test_data["mean_listing_price"] = all_price
return(test_data)
}
}
S_All_data = split(data,data$event_id)
Fin_S_All = lapply(S_All_data,function(x) pipeline(x,names(data)))
Fin = unsplit(Fin_S_All,data$event_id)
write.table(Fin, file='Final_Prediction.tsv', quote=FALSE, sep='\t')
kable(iris)
library(knitr)
kable(iris)
library (ggmap)
Map13 <- get_map(
c(lon=-77.02646, lat=38.89621),
zoom=13,maptype = "toner-lite"
)
ggmap(Map13)
Map16 <- get_map(
c(lon=-77.02646, lat=38.89621),
zoom=16,maptype = "toner-lite"
)
ggmap(Map17)
ggmap(Map16)
Map15 <- get_map(
c(lon=-77.02646, lat=38.89621),
zoom=15,maptype = "toner-lite"
)
ggmap(Map15)
ggmap(Map17)
Map17 <- get_map(
c(lon=-77.02646, lat=38.89621),
zoom=17,maptype = "toner-lite"
)
ggmap(Map17)
ggmap(Map16)
Map13 <- get_map(
c(lon=-77.02113, lat=38.89797),
zoom=13,maptype = "toner-lite"
)
library (ggmap)
Map13 <- get_map(
c(lon=-77.02113, lat=38.89797),
zoom=13,maptype = "toner-lite"
)
Map14 <- get_map(
c(lon=-77.02113, lat=38.89797),
zoom=14,maptype = "toner-lite"
)
Map15 <- get_map(
c(lon=-77.02113, lat=38.89797),
zoom=15,maptype = "toner-lite"
)
Map16 <- get_map(
c(lon=-77.02113, lat=38.89797),
zoom=16,maptype = "toner-lite"
)
Map17 <- get_map(
c(lon=-77.02113, lat=38.89797),
zoom=17,maptype = "toner-lite"
)
Map17 <- get_map(
c(lon=-77.02113, lat=38.89797),
zoom=17,maptype = "toner-lite"
)
save(Map13,Map14,Map15,Map16,Map17,file="Final_Map.rda")
x = rnorm(10)
x
x = rnorm(100)
hist(x)
hp<-qplot(x =x, fill=..count.., geom="histogram")
library(ggplot2)
hp<-qplot(x =x, fill=..count.., geom="histogram")
hp+scale_fill_gradient(low="blue", high="red")
hist(x,col=c(1,2,3,4,5))
hist(x,col=c(1,2,3,4,5,6,7,8))
11/29
library(spotifyr)
Client_id = "33798f8e03e74dce982681e7af1501c2"
Client_Secret = "468596cd85384d4ca45d2008e766c1a2"
Sys.setenv(SPOTIFY_CLIENT_ID = '33798f8e03e74dce982681e7af1501c2')
Sys.setenv(SPOTIFY_CLIENT_SECRET = '468596cd85384d4ca45d2008e766c1a2')
access_token = get_spotify_access_token()
beatles <- get_artist_audio_features('The Beatles')
shiny::runApp('Documents/Spotify_ANA/App')
runApp('Documents/Spotify_ANA/App')
runApp('Documents/Spotify_ANA/App')
runApp('Documents/Spotify_ANA/App')
runApp('Documents/Spotify_ANA/App')
shiny::runApp('Documents/Spotify_ANA/App_ToWeb')
runApp('Documents/Spotify_ANA/App_ToWeb')
shiny::runApp('Documents/Spotify_ANA/App_ToWeb')
setwd("~/Documents/Spotify_ANA/To Github")
library(shiny)
runApp("App")
